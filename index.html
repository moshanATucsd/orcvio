<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-10550309-8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-10550309-8');
</script>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
  body {
    font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 18px;
    margin-left: auto;
    margin-right: auto;
    width: 1100px;
  }

  h1 {
    font-weight: 300;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px;
    -moz-border-radius: 10px;
    -webkit-border-radius: 10px;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px;
    -moz-border-radius: 10px;
    -webkit-border-radius: 10px;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px;
    -moz-border-radius: 10px;
    -webkit-border-radius: 10px;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px;
    -moz-border-radius: 10px;
    -webkit-border-radius: 10px;
  }

  a:link,
  a:visited {
    color: #1367a7;
    text-decoration: none;
  }

  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big {
    /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
      0px 0px 1px 1px rgba(0, 0, 0, 0.35),
      /* The top layer shadow */
      5px 5px 0 0px #fff,
      /* The second layer */
      5px 5px 1px 1px rgba(0, 0, 0, 0.35),
      /* The second layer shadow */
      10px 10px 0 0px #fff,
      /* The third layer */
      10px 10px 1px 1px rgba(0, 0, 0, 0.35),
      /* The third layer shadow */
      15px 15px 0 0px #fff,
      /* The fourth layer */
      15px 15px 1px 1px rgba(0, 0, 0, 0.35),
      /* The fourth layer shadow */
      20px 20px 0 0px #fff,
      /* The fifth layer */
      20px 20px 1px 1px rgba(0, 0, 0, 0.35),
      /* The fifth layer shadow */
      25px 25px 0 0px #fff,
      /* The fifth layer */
      25px 25px 1px 1px rgba(0, 0, 0, 0.35);
    /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper {
    /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
      0px 0px 1px 1px rgba(0, 0, 0, 0.35),
      /* The top layer shadow */
      5px 5px 0 0px #fff,
      /* The second layer */
      5px 5px 1px 1px rgba(0, 0, 0, 0.35),
      /* The second layer shadow */
      10px 10px 0 0px #fff,
      /* The third layer */
      10px 10px 1px 1px rgba(0, 0, 0, 0.35);
    /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
    top: 50%;
    transform: translateY(-50%);
  }

  hr {
    border: 0;
    height: 1.5px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>

<html>

<head>
  <title>OrcVIO: Object residual constrained Visual-Inertial Odometry</title>
  <meta property="og:title" content="orcvio" />
  <meta property="og:image" content="" />
  <meta property="og:url" content="" />
  <style>
    code {
      font-family: Consolas, "courier new";
      color: darkcyan;
      background-color: #f1f1f1;
      padding: 2px;
      font-size: 105%;
    }
  </style>
</head>

<body>
  <br>

  <div id="photo" style="text-align: center">
    <img style="vertical-align:middle" src="logo.png" alt="">
    <span style="vertical-align:middle;font-size:35px">Object residual constrained Visual-Inertial Odometry</span>
  </div>

  <br><br>
  <table align=center width=800px>
    <tr>
      <td align=center width=100px>
        <center>
          <span style="font-size:20px"><a href="https://moshanatucsd.github.io/">Mo Shan</a></span>
        </center>
      </td>

      <td align=center width=100px>
        <center>
          <span style="font-size:20px"><a href="https://vikasdhiman.info/">Vikas Dhiman</a></span>
        </center>
      </td>

      <td align=center width=100px>
        <center>
          <span style="font-size:20px"><a href="https://fengqiaojun.github.io/publications.html">Qiaojun Feng</a></span>
        </center>
      </td>

      <td align=center width=100px>
        <center>
          <span style="font-size:20px"><a href="https://existentialrobotics.org/pages/people.html">Jinzhao Li</a></span>
        </center>
      </td>

      <td align=center width=100px>
        <center>
          <span style="font-size:20px"><a href="https://natanaso.github.io/">Nikolay Atanasov</a></span>
        </center>
      </td>
    </tr>
  </table>

  <table align=center width=700px>
    <tr>
      <td align=center width=100px>
        <center>
          <span style="font-size:20px">Department of Electrical and Computer Engineering <br> University of California,
            San Diego<br />IROS, 2020</span>
        </center>
      </td>
    </tr>
  </table>

  <br>

  <hr>
  <center>
    <h1>Overview</h1>
  </center>
  <hr>

  <table align=center width=600px>
    <tr>
      <td width=1000px>
        <center>
          <a href="orcvio-iros-digest.png"><img src="orcvio-iros-digest.png" height="400px"></img></href></a><br>
        </center>
      </td>
    </tr>
    <td width=600px>
      <center>
        <span style="font-size:14px"><i>Introduction of OrcVIO.</i>
      </center>
    </td>
    </tr>
  </table>

  <hr>
  <center>
    <h1>Animations</h1>
  </center>
  <hr>

  <table align=center width=600px>
    <tr>
      <td width=1000px>
        <center>
          <a href="sem_track_images.gif"><img src="sem_track_images.gif" height="400px"></img></href></a><br>
        </center>
      </td>
    </tr>
    <td width=1000px>
      <center>
        <span style="font-size:14px"><i>This animation shows color-coded object level tracks of semantic keypoints, and
            green tracks of geometric features.</i>
      </center>
    </td>
    </tr>
  </table>

  <table align=center width=600px>
    <tr>
      <td width=1000px>
        <center>
          <a href="bbox_images.gif"><img src="bbox_images.gif" height="400px"></img></href></a><br>
        </center>
      </td>
    </tr>
    <td width=1000px>
      <center>
        <span style="font-size:14px"><i>This animation shows the 2D IOU of bounding-boxes from annotation and those
            detected by YOLO. In the label, id means our object id, while gt means id in annotation.</i>
      </center>
    </td>
    </tr>
  </table>

  <table align=center width=600px>
    <tr>
      <td width=1000px>
        <center>
          <a href="reprojected_images.gif"><img src="reprojected_images.gif" height="400px"></img></href></a><br>
        </center>
      </td>
    </tr>
    <td width=1000px>
      <center>
        <span style="font-size:14px"><i>This animation shows the reprojected objects. The object state is reprojected on
            the image, where object detection is the blue rectangle, object shape is the red wireframe, and the green
            ellipse is the reprojection of the ellipsoid that we use to represent objects.</i>
      </center>
    </td>
    </tr>
  </table>

  <br><br>

  <hr>
  <center>
    <h1>Presentation</h1>
  </center>
  <hr>

  <center><h1>IROS 2020 short version</h1></center>
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="800" height="480" src="https://www.youtube.com/embed/D7o4-Xt0b0A"
              frameborder="0" allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>

  <center><h1>IROS 2020 long version</h1></center>
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="800" height="480" src="https://www.youtube.com/embed/TCL58gvo-FM"
              frameborder="0" allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>

  <table align=center width=800px>
    <tr>
      <center> <br>
        <span style="font-size:28px">&nbsp;<a href='OrcVIO IROS 2020 final presentation slides.pdf'>[Slides]</a>
          <span style="font-size:28px"></a></span>
          <br>
      </center>
    </tr>
  </table>

  <center>
    <h1>演讲视频</h1>
  </center>
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="800" height="480"
              src="https://www.youtube.com/embed/JTGCxuulRWM"
              frameborder="0" allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>
  <br>

  <table align=center width=800px>
    <tr>
      <center> <br>
        <span style="font-size:28px">&nbsp;<a href='OrcVIO IROS 2020 final presentation slides CN.pdf'>[讲义]</a>
          <span style="font-size:28px"></a></span>
          <br>
      </center>
    </tr>
  </table>

  <br>
  <hr>
  <!-- <table align=center width=550px> -->
  <table align=center width=800>
    <center>
      <h1>More results for OrcVIO</h1>
    </center>
    <hr>

    <center>
      <h1>Semantic keypoint detection</h1>
    </center>
    Our approach uses StarMap for semantic keypoint detection. As could be observed in the upper row in Figure below, it
    could handle a certain degree of viewpoint, scale, and visibility variation, since StarMap uses a large training set
    to prevent overfitting.
    Nonetheless, the lower row shows some failure cases due to occlusion or instance variation. Wrong detections or too
    few detections will cause troubles in our approach.
    <br> 
    <br> 
    <table align=center width=600px>
      <tr>
        <td width=1000px>
          <center>
            <a href="semantic_kps.jpg"><img src="semantic_kps.jpg" height="400px"></img></href></a><br>
          </center>
        </td>
      </tr>
      <td width=600px>
        <center>
          <span style="font-size:14px"><i>Semantic keypoint detection from starmap.</i>
        </center>
      </td>
      </tr>
    </table>
    <br>

    <center>
      <h1>Keypoint detection covariance</h1>
    </center>
    We use Monte Carlo Dropout to obtain the semantic keypoint covariances. Figure below shows how we insert the Dropout
    layer into the Starmap network and the average covariance obtained from a sampled KITTI dataset.
    <br> 
    <br> 
    <table align=center width=600px>
      <tr>
        <td width=1000px>
          <center>
            <a href="keypoint_cov1.jpg"><img src="keypoint_cov1.jpg" height="200px"></img></href></a><br>
          </center>
        </td>
      </tr>
      <td width=600px>
        <center>
          <span style="font-size:14px"><i>Semantic keypoint uncertainty obtained from approximate Bayesian inference
              through
              the stacked hourglass convolutional neural network.</i>
        </center>
      </td>
      </tr>
    </table>
    Below is a closer view of the keypoint covariance on one car.
    <br> 
    <br> 
    <table align=center width=600px>
      <tr>
        <td width=1000px>
          <center>
            <a href="kp_cov2.png"><img src="kp_cov2.png" height="400px"></img></href></a><br>
          </center>
        </td>
      </tr>
      <td width=600px>
        <center>
          <span style="font-size:14px"><i>Semantic keypoint uncertainty on one car.</i>
        </center>
      </td>
      </tr>
    </table>
    <br>

  </table>

  <center>
    <h1>Detection and tracking on KITTI</h1>
  </center>
  The front end could work with both colored images or grayscale images. Below is an exmaple of using color images as
  input.
  <br> 
  <br> 
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="800" height="480"
              src="https://www.youtube.com/embed/n6nZ75CoDhI"
              frameborder="0" allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>
  <br>


  <center>
    <h1>Object state reprojection on KITTI odometry sequences</h1>
  </center>
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="800" height="480" src="https://www.youtube.com/embed/Rf7xttuDuQ8" frameborder="0"
              allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>
  <br>

  <center>
    <h1>KITTI odometry 06</h1>
  </center>
  The bottom left window shows the object tracking for semantic keypoints and bounding boxes. 
  The right shows the trajectory estimation and object mapping.
  <br> 
  <br> 
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="800" height="480" src="https://www.youtube.com/embed/763iztZBH0g"
              frameborder="0" allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>
  <br>

  <center>
    <h1>KITTI raw data 09 26 0117</h1>
  </center>
  The top left window shows the semantic keypoints tracking, while the bottom left window shows the geometric features
  tracking. The right window shows the trajectory estimation and object mapping.
  <br> 
  <br> 
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="800" height="480" src="https://www.youtube.com/embed/AA50BqRzltk"
              frameborder="0" allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>
  <br>


  <center>
    <h1>Forest scene</h1>
  </center>
  This demo shows the peformance of OrcVIO in a forest using a RealSense sensor.
  The red line represents the estimated trajectory of OrcVIO. 
  The purple ellispoid is the covariance of the pose.
  <br> 
  <br> 
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="640" height="480" src="https://www.youtube.com/embed/HZ-m2e1MFqY"
              frameborder="0" allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>
  <br>

  <center><h1>Indoor scene with chairs and monitors</h1></center>
  This demo shows the construction of an object map for the lab scene with chairs and monitors, using a RealSense sensor.
  The red line is the estimated trajectory, and the axes mark the current pose. The black dots are the reconstructed geometric landmarks, whereas the green dots are the estimated semantic keypoints.
  The blue ellipsoids are the chairs and the orange ellipsoids are the monitors mapped by OrcVIO.
  <br> 
  <br> 
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="800" height="480"
              src="https://www.youtube.com/embed/HF3Tx-lQTuY" frameborder="0"
              allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>
  <br>

  <center>
    <h1>Outdoor scene at UCSD campus</h1>
  </center>
  This demo shows the construction of an object map for the outdoor scene with chairs, bikes, and cars, using an
  INDEMIND sensor. The red line is the estimated trajectory, and the axes mark the current pose. The green dots are the
  estimated semantic keypoints. The blue ellipsoids are the chairs mapped by OrcVIO, whereas the red ellipsoids are the
  bikes, and the black ellipsoids are the cars.
  <br> 
  <br> 
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="800" height="480" src="https://www.youtube.com/embed/5fodd3miodE"
              frameborder="0" allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>
  <br>



  <center>
    <h1>Object map with 40 cars in Unity simulator</h1>
  </center>
  <table align=center width=600px>
    <tr>
      <td width=1000px>
        <center>
          <a href="orcvio-unity-40cars.png"><img src="orcvio-unity-40cars.png" height="800px"></img></href></a><br>
        </center>
      </td>
    </tr>
    <td width=600px>
      <center>
        <span style="font-size:14px"><i>Upper row: Unity simulation scene. Lower row: reconstructed objects, where the
            orange line is the estimated trajectory, the green ellipsoids
            are the reconstructed cars, and the blue meshes are the groundtruth car positions.</i>
      </center>
    </td>
    </tr>
  </table>

  <center>
    <h1>Object map with car and door categories in Unity simulator</h1>
  </center>
  <table align=center width=600px>
    <tr>
      <td width=1000px>
        <center>
          <a href="orcvio_journal_intro.png"><img src="orcvio_journal_intro.png" height="800px"></img></href></a><br>
        </center>
      </td>
    </tr>
    <td width=600px>
      <center>
        <span style="font-size:14px"><i>We propose a tightly coupled visual-inertial odometry and object state
            optimization algorithm. (a) A simulated scene from Unity, where a quadrotor flies over cars and doors. (b)
            Color-coded semantic keypoint tracklets on cars and doors. (c) Estimated trajectory (green) that coincides
            with the groundtruth trajectory (red), and the object map with reconstructed cars (green ellipsoids), doors
            (red ellispoids), semantic keypoints (yellow spheres), and the groundtruth objects (blue meshes).</i>
      </center>
    </td>
    </tr>
  </table>

  <center>
    <h1>Demo with cars, doors, and barriers in Unity simulator</h1>
  </center>
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="800" height="480" src="https://www.youtube.com/embed/jf2wNwULPX8"
              frameborder="0" allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>
  <br>

  <br>
  <hr>
  <!-- <table align=center width=550px> -->
  <table align=center width=800>
    <center>
      <h1>More results for OrcVIO Lite</h1>
    </center>
    <hr>

    <center>
      <h1>KITTI odometry 06</h1>
    </center>
    OrcVIO Lite uses bounding box only and no semantic keypoints, more suitable for real time experiments. The test on
    KITTI odometry 06 uses grayscale images for both front end and back end.
    The red line is the estimated trajectory, while the purple ellipsoid is the covariance of the pose. The white points
    are the geometric landmarks, the colored dots are the active features. The black spheres are the reconstructed cars.
    <br> 
    <br> 
    <table align=center width=900px>
      <tr>
        <td width=600px>
          <center>
            <div class="video">
              <iframe width="800" height="480" src="https://www.youtube.com/embed/RF-_Q-xmdQQ"
                frameborder="0" allowfullscreen></iframe>
            </div>
          </center>
        </td>
      </tr>
    </table>
    <br>

    <center>
      <h1>Flea3 camera</h1>
    </center>
    OrcVIO Lite uses bounding box only and no semantic keypoints, more suitable for real time experiments. This test
    uses grayscale images from a Flea3 camera.
    The red line is the estimated trajectory, while the purple ellipsoid is the covariance of the pose. The white points
    are the geometric landmarks, the colored dots are the active features. The black spheres are the reconstructed cars.
    <br> 
    <br> 
    <table align=center width=900px>
      <tr>
        <td width=600px>
          <center>
            <div class="video">
              <iframe width="800" height="480"
                src="https://www.youtube.com/embed/8YtjsbS_Z1Y"
                frameborder="0" allowfullscreen></iframe>
            </div>
          </center>
        </td>
      </tr>
    </table>
    <br>

    <center>
      <h1>Jackal robot</h1>
    </center>
    OrcVIO Lite runs on a Jackal robot, which is equipped with a RealSense sensor.
    The yellow path is the VIO trajectory, whereas the red ellipsoids are the detected barrels. The marker size for barrels are exagerated for illustration purpose. 
    The barrel detection and tracking results are shown on the top left, where the bounding boxes show detections and the lines are the tracklets of the bounding boxes. 
    The tracklets are very long since the Jackal has a large viewpoint change. In this case the SORT tracker is modified to use centroid distance for affinity instead of IOU. 
    Due to the low quality IMU, the inertial data is not reliable and there is significant drift. The constant stop also makes it challenging for VIO. 
    Despite those difficulties, OrcVIO Lite is still able to localize the robot and map the barrels.
    <br>
    <br>
    <table align=center width=900px>
      <tr>
        <td width=600px>
          <center>
            <div class="video">
              <iframe width="800" height="480" src="https://www.youtube.com/embed/w47a8G9_mHU" frameborder="0"
                allowfullscreen></iframe>
            </div>
          </center>
        </td>
      </tr>
    </table>
    <br>

  </table>

  <br>
  <hr>
  <!-- <table align=center width=550px> -->
  <table align=center width=800>
    <center>
      <h1>More results for OrcVIO Stereo</h1>
    </center>
    <hr>

    <center>
      <h1>EuRoC V1 01</h1>
    </center>
    OrcVIO Stereo uses stereo camera instead of monocular camera to increase robustness. This demo shows its performance
    on EuRoC V1 01 sequence.
    The red line is ground-truth trajectory, while the blue line is the estimated trajectory.
    <br> 
    <br> 
    <table align=center width=900px>
      <tr>
        <td width=600px>
          <center>
            <div class="video">
              <iframe width="800" height="480" src="https://www.youtube.com/embed/8b4WYOeHOXM"
                frameborder="0" allowfullscreen></iframe>
            </div>
          </center>
        </td>
      </tr>
    </table>
    <br>

    <center>
      <h1>EuRoC MH 01</h1>
    </center>
    This demo shows the performance of OrcVIO Stereo on EuRoC MH 01 sequence.
    The red line is ground-truth trajectory, while the blue line is the estimated trajectory.
    <br> 
    <br> 
    <table align=center width=900px>
      <tr>
        <td width=600px>
          <center>
            <div class="video">
              <iframe width="800" height="480" src="https://www.youtube.com/embed/I6kNy2lyT0g"
                frameborder="0" allowfullscreen></iframe>
            </div>
          </center>
        </td>
      </tr>
    </table>
    <br>
    This demo shows the performance of OrcVIO Stereo Python version on EuRoC MH 01 sequence.
    The green line is ground-truth trajectory, while the black line is the estimated trajectory.
    <br> 
    <br> 
    <table align=center width=900px>
      <tr>
        <td width=600px>
          <center>
            <div class="video">
              <iframe width="800" height="480"
                src="https://www.youtube.com/embed/4kEocvKYbdk"
                frameborder="0" allowfullscreen></iframe>
            </div>
          </center>
        </td>
      </tr>
    </table>
    <br>

    <center>
      <h1>Jackal robot</h1>
    </center>
    OrcVIO Stereo runs on a Jackal robot, which is equipped with a RealSense sensor.
    The small linear acceleration due to constant velocity and limited angular velocity make this senario very challenging.
    A drift could be noticed when the Jackal runs over uneven terrain, e.g. curb.
    <br>
    <br>
    <table align=center width=900px>
      <tr>
        <td width=600px>
          <center>
            <div class="video">
              <iframe width="800" height="480" src="https://www.youtube.com/embed/Ob7DPogpsf4" frameborder="0"
                allowfullscreen></iframe>
            </div>
          </center>
        </td>
      </tr>
    </table>
    <br>

    <br>
    OrcVIO Stereo runs on a Jackal robot, with more features, in a loopy trajectory. 
    The accuracy is increased because there are more features, as can be seen in the completed loops with very small drifts.
    Due to small drift the point clouds are also reconstructed well, for instance the corridors can be clearly seen.  
    <br>
    <br>
    <table align=center width=900px>
      <tr>
        <td width=600px>
          <center>
            <div class="video">
              <iframe width="800" height="480" src="https://www.youtube.com/embed/uehVmwXUppQ" frameborder="0"
                allowfullscreen></iframe>
            </div>
          </center>
        </td>
      </tr>
    </table>
    <br>

  </table>


  <br>

  <center>
    <h1>Racecar</h1>
  </center>
  OrcVIO Stereo runs on a racecar, which is equipped with a RealSense D435i, in the lab.
  <br>
  <br>
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="800" height="480" src="https://www.youtube.com/embed/9MPWQscOFpc" frameborder="0"
              allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>
  <br>

  <br>
  OrcVIO Stereo runs on a racecar, which is equipped with a RealSense D435i. The mapping module 
  maps the chairs in the lab. 
  <br>
  <br>
  <table align=center width=900px>
    <tr>
      <td width=600px>
        <center>
          <div class="video">
            <iframe width="800" height="480" src="https://www.youtube.com/embed/zUu6654h_0s" frameborder="0"
              allowfullscreen></iframe>
          </div>
        </center>
      </td>
    </tr>
  </table>
  <br>

  </table>


  <hr>
  <table align=center width=900>
    <center>
      <h1>Publication</h1>
    </center>
    <hr>
    <tr>
      <pre xml:space="preserve">
        @inproceedings{shan2020orcvio,
          title={OrcVIO: Object residual constrained Visual-Inertial Odometry},
          author={Shan, Mo and Feng, Qiaojun and Atanasov, Nikolay},
          booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
          pages={5104--5111},
          year={2020},
          organization={IEEE}
        }                
      </pre>
      <table align=center width=800px>
        <tr>
          <center> <br>
            <span style="font-size:28px">&nbsp;<a href='0072.pdf'>[IROS version]</a>
              <span style="font-size:28px"></a></span>
              <br>
          </center>
        </tr>
      </table>

      <table align=center width=800px>
        <tr>
          <center> <br>
            <span style="font-size:28px">&nbsp;<a href='https://arxiv.org/abs/2007.15107'>[Journal version]</a>
              <span style="font-size:28px"></a></span>
              <br>
          </center>
        </tr>
      </table>
    </tr>

    <hr>


    <center>
      <h1>Codebase</h1>
    </center>
    <hr>

    <table align=center width=600px>
      <tr>
        <td width=600px>
          <center>
            <a href="code-summary.png"><img src="code-summary.png" height="300px"></img></href></a><br>
          </center>
        </td>
      </tr>
      <td width=600px>
        <center>
          <span style="font-size:14px"><i>We have made public different flavours of OrcVIO, include mono, stereo, mapping, mapping-lite, etc, as depicted in the summary above.</i>
        </center>
      </td>
      </tr>
    </table>

    <table align=center width=800px>
      <tr>
        <center> <br>
          <span style="font-size:28px">&nbsp;<a href='https://github.com/shanmo/OrcVIO-Stereo-Mapping'>[OrcVIO Demo in C++]</a>
            <span style="font-size:28px"></a></span>
            <br>
        </center>
      </tr>
    </table>

    <table align=center width=800px>
      <tr>
        <center> <br>
          <span style="font-size:28px">&nbsp;<a href='https://github.com/shanmo/orcvio-kitti-python'>[OrcVIO Demo in Python]</a>
            <span style="font-size:28px"></a></span>
            <br>
        </center>
      </tr>
    </table>

    <br>
    <hr>

    <table align=center width=1100px>
      <tr>
        <td>
          <left>
            <center>
              <h1>Acknowledgements</h1>
            </center>
            <hr>
            <p>We gratefully acknowledge support from ARL DCIST CRA W911NF-17-
              2-0181.</p>
            <p>This webpage template was borrowed from <a
                href="https://akanazawa.github.io/cmr/">https://akanazawa.github.io/cmr/</a>.</p>
            <p>The acronym of our method is inspired by <a
                href="http://classic.battle.net/war3/orc/">Warcraft III</a>.</p>
            <p>QR code generated from <a href="https://www.qrcode-monkey.com/">https://www.qrcode-monkey.com/</a>.</p>
          </left>
        </td>
      </tr>
    </table>

    <div id="photo" style="text-align: center">
      <img style="inline-block;width:200px;" src="qr-code.png" alt="">
    </div>

    <div style="display:inline-block;width:200px;">
      <script type="text/javascript"
        src="//rf.revolvermaps.com/0/0/7.js?i=556zb6z1e66&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;sx=0"
        async="async"></script>
    </div>

    <br><br>
</body>

</html>